{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = 0\n",
    "denominator = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a correct implementation of the function generate_equations which passes basic tests.: 1/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator += 1\n",
    "denominator += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a correct implementation of the function sentence_to_ids. It appends special end symbol at the end of the sequence and placeholders if the length of input is smaller than desirable length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator += 1\n",
    "denominator += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders self.ground_truth, self.ground_truth_lengths and self.learning_rate_ph are initialized correctly in the function declare_placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator += 1\n",
    "denominator += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders self.embeddings and self.input_batch_embedded are initialized correctly in the function create_embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator += 1\n",
    "denominator += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines in the functions build_encoder and build_decoder are filled in correctly and the following variable are created with corresponding values:\n",
    "\n",
    "encoder_cell and decoder_cell as RNN cells; DropoutWrapper is used for both of them;\n",
    "dynamic_rnn function is used for creating encoder;\n",
    "self.ground_truth_embedded is initialized as embeddings_lookup using self.embeddings;\n",
    "infer_helper as helper from tf.contrib.seq2seq (e.g. GreedyEmbeddingHelper);\n",
    "decoder as BasicDecoder from tf.contrib.seq2seq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator += 1\n",
    "denominator += 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines in the functions compute_loss and perform_optimization are filled in correctly and the following variables are created:\n",
    "\n",
    "self.loss is defined as sequence_loss which operates with logits (self.train_outputs.rnn_output), self.ground_truth and the defined weights.\n",
    "self.train_op is initialised as follows: self.loss is used as a loss function, value of the learning rate is the value of corresponding placeholder, optimizer is Adam, gradients are clipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator += 3\n",
    "denominator += 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions predict_for_batch and predict_for_batch_with_loss are filled in correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator += 1\n",
    "denominator += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are experiments of the network training present in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator += 3\n",
    "denominator += 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final evaluation scores are present in the notebook. MAE score for the best model is around 50 or lower on the test data and invalid_number_prediction_count always equals zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator += 0\n",
    "denominator += 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value of the loss function is significantly greater at the beginning of the training (e.g. about 2.70 at the beginning and about 1 at the end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator += 1\n",
    "denominator += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value of the loss function is significantly greater at the beginning of the training (e.g. about 1.56 after the first epoch and about 0.96 at the end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator += 0\n",
    "denominator += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the difference of MAE is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator += 1\n",
    "denominator += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerator / denominator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
